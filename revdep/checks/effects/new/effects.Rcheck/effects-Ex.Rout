
R version 4.4.1 (2024-06-14 ucrt) -- "Race for Your Life"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "effects"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('effects')
Loading required package: carData
Warning: package 'carData' was built under R version 4.4.3
lattice theme set by effectsTheme()
See ?effectsTheme for details.
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("effCoef")
> ### * effCoef
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: effCoef
> ### Title: Function to get coefficient estimates from regression models for
> ###   use in the effects package.
> ### Aliases: effCoef effCoef.default
> ### Keywords: models
> 
> ### ** Examples
> 
> m1 <- lm(prestige ~ type + income + education, Duncan)
> effCoef(m1)
(Intercept)    typeprof      typewc      income   education 
 -0.1850278  16.6575134 -14.6611334   0.5975465   0.3453193 
> 
> 
> 
> cleanEx()
> nameEx("effect")
> ### * effect
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: effect
> ### Title: Functions For Constructing Effect Displays
> ### Aliases: effect effect.default Effect Effect.default Effect.lm
> ###   Effect.multinom Effect.merMod Effect.mlm Effect.poLCA Effect.polr
> ###   Effect.svyglm allEffects allEffects.default
> ### Keywords: hplot models
> 
> ### ** Examples
> 
> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
+                   data=Cowles, family=binomial)
> eff.cowles <- allEffects(mod.cowles, xlevels=list(extraversion=seq(0, 24, 6)),
+                    fixed.predictors=list(given.values=c(sexmale=0.5)))
> eff.cowles
 model: volunteer ~ sex + neuroticism * extraversion

 sex effect
sex
   female      male 
0.4409440 0.3811939 

 neuroticism*extraversion effect
           extraversion
neuroticism          0         6        12        18        24
         0  0.07714514 0.1852939 0.3822555 0.6273613 0.8208051
         6  0.13977939 0.2452491 0.3938629 0.5651049 0.7221029
         12 0.24003937 0.3170543 0.4055913 0.5007251 0.5958063
         18 0.38041106 0.3987751 0.4174285 0.4363211 0.4554004
         24 0.54409911 0.4865532 0.4293616 0.3739958 0.3217439
> as.data.frame(eff.cowles[[2]])
   neuroticism extraversion        fit         se      lower     upper
1            0            0 0.07714514 0.03544746 0.03054149 0.1815450
2            6            0 0.13977939 0.03618750 0.08264123 0.2266619
3           12            0 0.24003937 0.03427320 0.17935815 0.3134100
4           18            0 0.38041106 0.06752491 0.25935743 0.5184175
5           24            0 0.54409911 0.11919711 0.31757069 0.7537420
6            0            6 0.18529385 0.04353081 0.11445117 0.2858329
7            6            6 0.24524908 0.03245365 0.18728469 0.3142173
8           12            6 0.31705428 0.02350249 0.27287613 0.3647965
9           18            6 0.39877514 0.03886271 0.32557435 0.4767987
10          24            6 0.48655318 0.06805930 0.35714862 0.6177859
11           0           12 0.38225550 0.03408155 0.31802405 0.4508829
12           6           12 0.39386288 0.02034456 0.35477210 0.4343613
13          12           12 0.40559131 0.01354276 0.37934728 0.4323861
14          18           12 0.41742847 0.02243505 0.37421939 0.4619438
15          24           12 0.42936156 0.03742270 0.35805408 0.5037267
16           0           18 0.62736125 0.05771307 0.50926308 0.7319953
17           6           18 0.56510493 0.03487887 0.49593640 0.6318283
18          12           18 0.50072506 0.02426666 0.45329968 0.5481374
19          18           18 0.43632113 0.04172773 0.35694714 0.5190974
20          24           18 0.37399577 0.06548426 0.25667643 0.5082717
21           0           24 0.82080514 0.06634982 0.65422645 0.9172802
22           6           24 0.72210289 0.05285633 0.60794075 0.8132350
23          12           24 0.59580633 0.04211315 0.51131719 0.6749735
24          18           24 0.45540044 0.07319364 0.31923199 0.5985810
25          24           24 0.32174395 0.10666914 0.15396870 0.5528690
> 
> 
> # a nested model:
> 
> mod <- lm(log(prestige) ~ income:type + education, data=Prestige)
> 
> plot(Effect(c("income", "type"), mod, transformation=list(link=log, inverse=exp)),
+      axes=list(y=list(lab="prestige")))
> 
> 
> if (require(nnet)){
+     mod.beps <- multinom(vote ~ age + gender + economic.cond.national +
+                              economic.cond.household + Blair + Hague + Kennedy +
+                              Europe*political.knowledge, data=BEPS)
+ 
+     plot(Effect(c("Europe", "political.knowledge"), mod.beps,
+                 xlevels=list(Europe=1:11, political.knowledge=0:3),
+                 fixed.predictors=list(given.values=c(gendermale=0.5))),
+          lines=list(col=c("blue", "red", "orange")),
+          axes=list(x=list(rug=FALSE), y=list(style="stacked")))
+ 
+ }
Loading required package: nnet
Warning: package 'nnet' was built under R version 4.4.3
# weights:  36 (22 variable)
initial  value 1675.383740 
iter  10 value 1240.047788
iter  20 value 1163.199642
iter  30 value 1116.519687
final  value 1116.519666 
converged
> 
> if (require(MASS)){
+     mod.wvs <- polr(poverty ~ gender + religion + degree + country*poly(age,3),
+                     data=WVS)
+ 
+     plot(Effect(c("country", "age"), mod.wvs),
+          axes=list(y=list(style="stacked")))
+ 
+ }
Loading required package: MASS
Warning: package 'MASS' was built under R version 4.4.3

Re-fitting to get Hessian

> 
> 
> mod.pres <- lm(prestige ~ log(income, 10) + poly(education, 3) + poly(women, 2),
+                data=Prestige)
> eff.pres <- allEffects(mod.pres, xlevels=50)
> plot(eff.pres)
> plot(eff.pres[1],
+      axes=list(x=list(income=list(
+              transform=list(trans=log10, inverse=function(x) 10^x),
+              ticks=list(at=c(1000, 2000, 5000, 10000, 20000))
+     ))))
> 
> if (require(nlme)){ # for gls()
+     mod.hart <- gls(fconvict ~ mconvict + tfr + partic + degrees, data=Hartnagel,
+                     correlation=corARMA(p=2, q=0), method="ML")
+     plot(allEffects(mod.hart))
+     detach(package:nlme)
+ }
Loading required package: nlme
Warning: package 'nlme' was built under R version 4.4.3
> 
> if (require(lme4)){
+     data(cake, package="lme4")
+     fm1 <- lmer(angle ~ recipe * temperature + (1|recipe:replicate), cake,
+                 REML = FALSE)
+     plot(Effect(c("recipe", "temperature"), fm1))
+     if (any(grepl("pbkrtest", search()))) detach(package:pbkrtest)
+     detach(package:lme4)
+ }
Loading required package: lme4
Warning: package 'lme4' was built under R version 4.4.3
Loading required package: Matrix
Warning: package 'Matrix' was built under R version 4.4.3
> 
> 
> 
> # mlm example
> if (require(heplots)) {
+     data(NLSY, package="heplots")
+     mod <- lm(cbind(read,math) ~ income+educ, data=NLSY)
+     eff.inc <- Effect("income", mod)
+     plot(eff.inc)
+     eff.edu <- Effect("educ", mod)
+     plot(eff.edu, axes=list(x=list(rug=FALSE), grid=TRUE))
+     detach(package:heplots)
+ }
Loading required package: heplots
Loading required package: broom
Warning: package 'broom' was built under R version 4.4.3
> 
> # svyglm() example (adapting an example from the survey package)
> 
> 
> # component + residual plot examples
> 
> 
> #  artificial data
> 
> set.seed(12345)
> x1 <- runif(500, -75, 100)
> x2 <- runif(500, -75, 100)
> y <- 10 + 5*x1 + 5*x2 + x1^2 + x2^2 + x1*x2 + rnorm(500, 0, 1e3)
> Data <- data.frame(y, x1, x2)
> mod.1 <- lm(y ~ poly(x1, x2, degree=2, raw=TRUE), data=Data)
> # raw=TRUE necessary for safe prediction
> mod.2 <- lm(y ~ x1*x2, data=Data)
> mod.3 <- lm(y ~ x1 + x2, data=Data)
> 
> plot(Effect(c("x1", "x2"), mod.1, residuals=TRUE)) # correct model
> plot(Effect(c("x1", "x2"), mod.2, residuals=TRUE)) # wrong model
> plot(Effect(c("x1", "x2"), mod.3, residuals=TRUE)) # wrong model
> 
> 
> 
> cleanEx()

detaching 'package:broom', 'package:Matrix', 'package:MASS',
  'package:nnet'

> nameEx("effectsHexsticker")
> ### * effectsHexsticker
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: effectsHexsticker
> ### Title: View the Official Hex Sticker for the effects Package
> ### Aliases: effectsHexsticker
> ### Keywords: misc
> 
> ### ** Examples
> 
> ## Not run: 
> ##D effectsHexsticker()
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("effectsTheme")
> ### * effectsTheme
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: effectsTheme
> ### Title: Set the lattice Theme for Effect Plots
> ### Aliases: effectsTheme
> ### Keywords: utilities device
> 
> ### ** Examples
> 
> ## Not run: 
> ##D lattice::trellis.par.set(effectsTheme())
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("plot.effect")
> ### * plot.effect
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.effects
> ### Title: Plots of Effects and Predictor Effects
> ### Aliases: plot.effect plot.effects plot.predictoreff
> ###   plot.predictorefflist plot.eff plot.effpoly plot.efflist
> ###   plot.mlm.efflist [.efflist
> ### Keywords: hplot models
> 
> ### ** Examples
> 
> # also see examples in ?effect
> 
> # plot predictorEffects
> mod <- lm(prestige ~ education + log(income)*type + women, Prestige)
> plot(predictorEffects(mod, ~ income), axes=list(grid=TRUE))
> plot(predictorEffects(mod, ~ income), lines=list(multiline=TRUE),
+                                                  axes=list(grid=TRUE))
> plot(predictorEffects(mod, ~ type), lines=list(multiline=TRUE),
+                                                  axes=list(grid=TRUE),
+                                                  confint=list(style="bars"))
> 
> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
+                   data=Cowles, family=binomial)
> eff.cowles <- allEffects(mod.cowles, xlevels=list(extraversion=seq(0, 24, 6)))
> eff.cowles
 model: volunteer ~ sex + neuroticism * extraversion

 sex effect
sex
   female      male 
0.4409440 0.3811939 

 neuroticism*extraversion effect
           extraversion
neuroticism          0         6        12        18        24
         0  0.07801015 0.1871256 0.3851139 0.6301828 0.8225762
         6  0.14123920 0.2474935 0.3967524 0.5680733 0.7245221
         12 0.24225139 0.3196775 0.4085089 0.5037470 0.5987140
         18 0.38326427 0.4016768 0.4203710 0.4392964 0.4584000
         24 0.54709597 0.4895735 0.4323257 0.3768301 0.3243875
> as.data.frame(eff.cowles[[2]]) # neuroticism*extraversion interaction
   neuroticism extraversion        fit         se      lower     upper
1            0            0 0.07801015 0.03581560 0.03089795 0.1833655
2            6            0 0.14123920 0.03650729 0.08355744 0.2287989
3           12            0 0.24225139 0.03447835 0.18116011 0.3159939
4           18            0 0.38326427 0.06769318 0.26172607 0.5213832
5           24            0 0.54709597 0.11903994 0.32024065 0.7559411
6            0            6 0.18712561 0.04389813 0.11563481 0.2884016
7            6            6 0.24749348 0.03267915 0.18908978 0.3168869
8           12            6 0.31967748 0.02356742 0.27535035 0.3675214
9           18            6 0.40167680 0.03886339 0.32840174 0.4796253
10          24            6 0.48957346 0.06798133 0.36010512 0.6204558
11           0           12 0.38511395 0.03435145 0.32033800 0.4542343
12           6           12 0.39675238 0.02050553 0.35733819 0.4375541
13          12           12 0.40850887 0.01345159 0.38243044 0.4351127
14          18           12 0.42037096 0.02222578 0.37753313 0.4644428
15          24           12 0.43232574 0.03722316 0.36132026 0.5062251
16           0           18 0.63018280 0.05767002 0.51199718 0.7345837
17           6           18 0.56807333 0.03491556 0.49877301 0.6348075
18          12           18 0.50374699 0.02416959 0.45648325 0.5509439
19          18           18 0.43929637 0.04160432 0.36006784 0.5217446
20          24           18 0.37683013 0.06549783 0.25928430 0.5109089
21           0           24 0.82257620 0.06589496 0.65677676 0.9182525
22           6           24 0.72452207 0.05262356 0.61069713 0.8151407
23          12           24 0.59871398 0.04195091 0.51446626 0.6775069
24          18           24 0.45839998 0.07313475 0.32209771 0.6012262
25          24           24 0.32438752 0.10700301 0.15569491 0.5555828
> 
> plot(eff.cowles, 'sex', axes=list(grid=TRUE,
+                                   y=list(lab="Prob(Volunteer)"),
+                                   x=list(rotate=90)),
+                         lines=list(lty=0))
> 
> plot(eff.cowles, 'neuroticism:extraversion',
+      axes=list(y=list(lab="Prob(Volunteer)",
+         ticks=list(at=c(.1,.25,.5,.75,.9)))))
> 
> plot(Effect(c("neuroticism", "extraversion"), mod.cowles,
+             se=list(type="Scheffe"),
+             xlevels=list(extraversion=seq(0, 24, 6))),
+      axes=list(y=list(lab="Prob(Volunteer)",
+         ticks=list(at=c(.1,.25,.5,.75,.9)))))
> 
> 
> if (require(nnet)){
+     mod.beps <- multinom(vote ~ age + gender + economic.cond.national +
+                              economic.cond.household + Blair + Hague + Kennedy +
+                              Europe*political.knowledge, data=BEPS)
+ 
+     plot(effect("Europe*political.knowledge", mod.beps,
+                 xlevels=list(political.knowledge=0:3),
+                 fixed.predictors=list(given.values=c(gendermale=0.5))),
+          axes=list(y=list(style="stacked"), x=list(rug=FALSE), grid=TRUE),
+          lines=list(col=c("blue", "red", "orange")))
+ }
Loading required package: nnet
Warning: package 'nnet' was built under R version 4.4.3
# weights:  36 (22 variable)
initial  value 1675.383740 
iter  10 value 1240.047788
iter  20 value 1163.199642
iter  30 value 1116.519687
final  value 1116.519666 
converged
> 
> if (require(MASS)){
+     mod.wvs <- polr(poverty ~ gender + religion + degree + country*poly(age,3),
+                     data=WVS)
+     plot(effect("country*poly(age, 3)", mod.wvs))
+ 
+ }
Loading required package: MASS
Warning: package 'MASS' was built under R version 4.4.3

Re-fitting to get Hessian

> 
> mod.pres <- lm(prestige ~ log(income, 10) + poly(education, 3) + poly(women, 2),
+                data=Prestige)
> eff.pres <- allEffects(mod.pres)
> plot(eff.pres[1],
+      axes=list(x=list(income=list(transform=list(
+          trans=log10, inverse=function(x) 10^x),
+          ticks=list(at=c(1000, 2000, 5000, 10000, 20000))))))
>          
> mod <- lm(log(prestige) ~ income:type + education, data=Prestige)
> p1 <- predictorEffects(mod, ~ income)
> # log-scale for response
> plot(p1, lines=list(multiline=TRUE)) 
> # log-scale, with arithmetic tick marks
> plot(p1, lines=list(multiline=TRUE), 
+      axes=list(y=list(transform=list(trans=log, inverse = exp), 
+                       lab="prestige", type="rescale")))
> # arithmetic scale and tick marks, with other arguments
> plot(p1, lines=list(multiline=TRUE), grid=TRUE,
+      lattice=list(key.args=list(space="right", border=TRUE)),
+      axes=list(y=list(transform=exp, lab="prestige")))
> 
> 
> 
> cleanEx()

detaching 'package:MASS', 'package:nnet'

> nameEx("predictorEffects")
> ### * predictorEffects
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predictorEffects
> ### Title: Functions For Computing Predictor Effects
> ### Aliases: predictorEffect predictorEffect.poLCA predictorEffect.svyglm
> ###   predictorEffect.default predictorEffects predictorEffects.poLCA
> ###   predictorEffects.default
> ### Keywords: hplot models
> 
> ### ** Examples
> 
> mod <- lm(prestige ~ type*(education + income) + women, Prestige)
> plot(predictorEffect("income", mod))
> plot(predictorEffects(mod, ~ education + income + women))
> 
> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion, data=Cowles, family=binomial)
> plot(predictorEffects(mod.cowles, xlevels=4))
> plot(predictorEffect("neuroticism", mod.cowles, xlevels=list(extraversion=seq(5, 20, by=5))),
+      axes=list(grid=TRUE,
+                x=list(rug=FALSE),
+                y=list(lab="Probability of Vounteering")),
+      lines=list(multiline=TRUE), 
+      type="response")
> predictorEffects(mod.cowles, focal.levels=4, xlevels=4)

 sex predictor effect

 sex effect
sex
   female      male 
0.4409440 0.3811939 

 neuroticism predictor effect

 neuroticism*extraversion effect
           extraversion
neuroticism         2         9        16        23
         0  0.1056408 0.2752101 0.5496776 0.7969085
         8  0.1999369 0.3322754 0.4977164 0.6636590
         16 0.3458537 0.3947292 0.4458046 0.4980506
         24 0.5279854 0.4608204 0.3950486 0.3328688

 extraversion predictor effect

 extraversion*neuroticism effect
            neuroticism
extraversion         0         8        16        24
          2  0.1056408 0.1999369 0.3458537 0.5279854
          9  0.2752101 0.3322754 0.3947292 0.4608204
          16 0.5496776 0.4977164 0.4458046 0.3950486
          23 0.7969085 0.6636590 0.4980506 0.3328688
> 
> # svyglm() example (adapting an example from the survey package)
> 
> 
> 
> cleanEx()
> nameEx("summary.effect")
> ### * summary.effect
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.eff
> ### Title: Summarizing and Printing Effects
> ### Aliases: print.eff print.effpoly print.efflatent print.efflist
> ###   print.mlm.efflist print.summary.eff summary.eff summary.effpoly
> ###   summary.efflatent summary.efflist summary.mlm.efflist
> ###   as.data.frame.eff as.data.frame.effpoly as.data.frame.efflatent
> ###   as.data.frame.efflist vcov.eff
> ### Keywords: hplot models
> 
> ### ** Examples
> 
> 
> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
+                   data=Cowles, family=binomial)
> eff.cowles <- predictorEffects(mod.cowles)
> print(eff.cowles)

 sex predictor effect

 sex effect
sex
   female      male 
0.4409440 0.3811939 

 neuroticism predictor effect

 neuroticism*extraversion effect
           extraversion
neuroticism         2       7.2        12        18        23
       0    0.1056408 0.2194941 0.3851139 0.6301828 0.7969085
       0.49 0.1100566 0.2236521 0.3860597 0.6252398 0.7900087
       0.98 0.1146332 0.2278657 0.3870063 0.6202705 0.7829383
       1.47 0.1193747 0.2321351 0.3879538 0.6152759 0.7756974
       1.96 0.1242847 0.2364599 0.3889021 0.6102569 0.7682864
       2.45 0.1293671 0.2408400 0.3898513 0.6052144 0.7607061
       2.94 0.1346253 0.2452753 0.3908013 0.6001495 0.7529576
       3.43 0.1400628 0.2497653 0.3917521 0.5950630 0.7450423
       3.92 0.1456830 0.2543098 0.3927037 0.5899560 0.7369620
       4.41 0.1514890 0.2589084 0.3936562 0.5848296 0.7287188
       4.9  0.1574837 0.2635609 0.3946095 0.5796847 0.7203153
       5.39 0.1636699 0.2682666 0.3955635 0.5745225 0.7117545
       5.88 0.1700500 0.2730253 0.3965184 0.5693439 0.7030396
       6.37 0.1766264 0.2778363 0.3974741 0.5641501 0.6941746
       6.86 0.1834008 0.2826991 0.3984305 0.5589423 0.6851633
       7.35 0.1903750 0.2876131 0.3993877 0.5537214 0.6760105
       7.84 0.1975503 0.2925777 0.4003457 0.5484886 0.6667210
       8.33 0.2049275 0.2975922 0.4013045 0.5432451 0.6573002
       8.82 0.2125073 0.3026559 0.4022640 0.5379920 0.6477538
       9.31 0.2202897 0.3077680 0.4032242 0.5327305 0.6380879
       9.8  0.2282746 0.3129276 0.4041852 0.5274617 0.6283089
       10.3 0.2366302 0.3182408 0.4051666 0.5220790 0.6182209
       10.8 0.2451946 0.3236017 0.4061487 0.5166912 0.6080300
       11.3 0.2539657 0.3290093 0.4071316 0.5112995 0.5977440
       11.8 0.2629414 0.3344626 0.4081152 0.5059052 0.5873712
       12.2 0.2702672 0.3388574 0.4089026 0.5015887 0.5790163
       12.7 0.2796030 0.3443901 0.4098876 0.4961928 0.5685093
       13.2 0.2891336 0.3499654 0.4108732 0.4907978 0.5579402
       13.7 0.2988542 0.3555819 0.4118596 0.4854049 0.5473184
       14.2 0.3087597 0.3612385 0.4128467 0.4800155 0.5366533
       14.7 0.3188442 0.3669339 0.4138345 0.4746306 0.5259545
       15.2 0.3291013 0.3726667 0.4148230 0.4692517 0.5152319
       15.7 0.3395239 0.3784355 0.4158122 0.4638799 0.5044952
       16.2 0.3501043 0.3842388 0.4168020 0.4585165 0.4937544
       16.7 0.3608343 0.3900754 0.4177925 0.4531627 0.4830194
       17.1 0.3695201 0.3947675 0.4185854 0.4488874 0.4744421
       17.6 0.3804967 0.4006599 0.4195771 0.4435539 0.4637423
       18.1 0.3915969 0.4065812 0.4205695 0.4382334 0.4530758
       18.6 0.4028104 0.4125297 0.4215625 0.4329270 0.4424522
       19.1 0.4141264 0.4185039 0.4225561 0.4276360 0.4318810
       19.6 0.4255338 0.4245021 0.4235504 0.4223615 0.4213715
       20.1 0.4370210 0.4305226 0.4245453 0.4171047 0.4109327
       20.6 0.4485762 0.4365638 0.4255408 0.4118666 0.4005735
       21.1 0.4601871 0.4426238 0.4265369 0.4066484 0.3903025
       21.6 0.4718414 0.4487009 0.4275336 0.4014512 0.3801278
       22   0.4811877 0.4535738 0.4283313 0.3973093 0.3720627
       22.5 0.4928882 0.4596773 0.4293291 0.3921526 0.3620811
       23   0.5045966 0.4657929 0.4303274 0.3870198 0.3522171
       23.5 0.5162999 0.4719189 0.4313263 0.3819120 0.3424775
       24   0.5279854 0.4780532 0.4323257 0.3768301 0.3328688

 extraversion predictor effect

 extraversion*neuroticism effect
            neuroticism
extraversion         0         6        12        18        24
        2    0.1056408 0.1716423 0.2665883 0.3893675 0.5279854
        2.43 0.1126123 0.1788194 0.2720193 0.3906843 0.5238639
        2.86 0.1199820 0.1862292 0.2775191 0.3920027 0.5197392
        3.29 0.1277647 0.1938735 0.2830869 0.3933227 0.5156118
        3.71 0.1357783 0.2015678 0.2885899 0.3946135 0.5115783
        4.14 0.1444174 0.2096795 0.2942893 0.3959365 0.5074472
        4.57 0.1535085 0.2180284 0.3000538 0.3972611 0.5033152
        5    0.1630629 0.2266145 0.3058823 0.3985872 0.4991826
        5.43 0.1730903 0.2354369 0.3117735 0.3999147 0.4950502
        5.86 0.1835991 0.2444942 0.3177263 0.4012438 0.4909184
        6.29 0.1945958 0.2537843 0.3237393 0.4025743 0.4867879
        6.71 0.2058120 0.2630804 0.3296692 0.4038752 0.4827552
        7.14 0.2177842 0.2728216 0.3357969 0.4052085 0.4786288
        7.57 0.2302510 0.2827852 0.3419805 0.4065432 0.4745053
        8    0.2432094 0.2929660 0.3482182 0.4078793 0.4703853
        8.43 0.2566540 0.3033583 0.3545084 0.4092168 0.4662693
        8.86 0.2705761 0.3139556 0.3608493 0.4105556 0.4621579
        9.29 0.2849639 0.3247505 0.3672391 0.4118957 0.4580517
        9.71 0.2994523 0.3354774 0.3735257 0.4132059 0.4540464
        10.1 0.3132758 0.3455928 0.3794018 0.4144237 0.4503325
        10.6 0.3314929 0.3587675 0.3869871 0.4159864 0.4455793
        11   0.3464424 0.3694640 0.3930952 0.4172378 0.4417838
        11.4 0.3617013 0.3802903 0.3992370 0.4184903 0.4379951
        11.9 0.3811714 0.3939913 0.4069588 0.4200574 0.4332694
        12.3 0.3970307 0.4050746 0.4131698 0.4213122 0.4294976
        12.7 0.4131094 0.4162555 0.4194084 0.4225680 0.4257339
        13.1 0.4293755 0.4275232 0.4256730 0.4238248 0.4219788
        13.6 0.4499206 0.4417130 0.4335371 0.4253973 0.4172977
        14   0.4664841 0.4531350 0.4398528 0.4266563 0.4135634
        14.4 0.4831219 0.4646065 0.4461881 0.4279163 0.4098390
        14.9 0.5039674 0.4789972 0.4541315 0.4294926 0.4051981
        15.3 0.5206374 0.4905362 0.4605034 0.4307547 0.4014975
        15.7 0.5372616 0.5020852 0.4668881 0.4320176 0.3978081
        16.1 0.5538033 0.5136320 0.4732838 0.4332815 0.3941303
        16.6 0.5743100 0.5280436 0.4812904 0.4348625 0.3895498
        17   0.5905367 0.5395405 0.4877028 0.4361283 0.3858994
        17.4 0.6065686 0.5509955 0.4941193 0.4373949 0.3822618
        17.9 0.6262867 0.5652371 0.5021424 0.4389793 0.3777333
        18.3 0.6417680 0.5765545 0.5085602 0.4402478 0.3741258
        18.7 0.6569592 0.5877922 0.5149753 0.4415170 0.3705322
        19.1 0.6718357 0.5989391 0.5213854 0.4427870 0.3669528
        19.6 0.6899547 0.6127288 0.5293879 0.4443755 0.3624993
        20   0.7040448 0.6236332 0.5357792 0.4456471 0.3589533
        20.4 0.7177566 0.6344137 0.5421589 0.4469195 0.3554227
        20.9 0.7343427 0.6477011 0.5501137 0.4485109 0.3510314
        21.3 0.7471549 0.6581701 0.5564594 0.4497848 0.3475365
        21.7 0.7595515 0.6684872 0.5627867 0.4510593 0.3440579
        22.1 0.7715261 0.6786450 0.5690937 0.4523345 0.3405959
        22.6 0.7858950 0.6911076 0.5769458 0.4539294 0.3362923
        23   0.7969085 0.7008823 0.5831997 0.4552060 0.3328688
> print(eff.cowles[["neuroticism"]], type="link")

 neuroticism predictor effect

 neuroticism*extraversion effect
           extraversion
neuroticism           2         7.2         12           18          23
       0    -2.13606239 -1.26861675 -0.4678977  0.533001102  1.36708344
       0.49 -2.09016325 -1.24450930 -0.4639057  0.511848911  1.32497771
       0.98 -2.04426412 -1.22040184 -0.4599136  0.490696719  1.28287198
       1.47 -1.99836498 -1.19629439 -0.4559215  0.469544527  1.24076625
       1.96 -1.95246584 -1.17218694 -0.4519295  0.448392335  1.19866052
       2.45 -1.90656671 -1.14807948 -0.4479374  0.427240143  1.15655478
       2.94 -1.86066757 -1.12397203 -0.4439454  0.406087951  1.11444905
       3.43 -1.81476843 -1.09986457 -0.4399533  0.384935759  1.07234332
       3.92 -1.76886930 -1.07575712 -0.4359613  0.363783567  1.03023759
       4.41 -1.72297016 -1.05164966 -0.4319692  0.342631375  0.98813186
       4.9  -1.67707103 -1.02754221 -0.4279771  0.321479183  0.94602612
       5.39 -1.63117189 -1.00343475 -0.4239851  0.300326992  0.90392039
       5.88 -1.58527275 -0.97932730 -0.4199930  0.279174800  0.86181466
       6.37 -1.53937362 -0.95521984 -0.4160010  0.258022608  0.81970893
       6.86 -1.49347448 -0.93111239 -0.4120089  0.236870416  0.77760320
       7.35 -1.44757534 -0.90700493 -0.4080169  0.215718224  0.73549746
       7.84 -1.40167621 -0.88289748 -0.4040248  0.194566032  0.69339173
       8.33 -1.35577707 -0.85879002 -0.4000328  0.173413840  0.65128600
       8.82 -1.30987793 -0.83468257 -0.3960407  0.152261648  0.60918027
       9.31 -1.26397880 -0.81057512 -0.3920486  0.131109456  0.56707454
       9.8  -1.21807966 -0.78646766 -0.3880566  0.109957264  0.52496880
       10.3 -1.17124381 -0.76186822 -0.3839831  0.088373395  0.48200377
       10.8 -1.12440796 -0.73726877 -0.3799095  0.066789526  0.43903874
       11.3 -1.07757210 -0.71266933 -0.3758360  0.045205657  0.39607371
       11.8 -1.03073625 -0.68806989 -0.3717625  0.023621787  0.35310867
       12.2 -0.99326757 -0.66839033 -0.3685037  0.006354692  0.31873665
       12.7 -0.94643171 -0.64379089 -0.3644301 -0.015229177  0.27577161
       13.2 -0.89959586 -0.61919144 -0.3603566 -0.036813047  0.23280658
       13.7 -0.85276001 -0.59459200 -0.3562831 -0.058396916  0.18984155
       14.2 -0.80592415 -0.56999256 -0.3522095 -0.079980785  0.14687652
       14.7 -0.75908830 -0.54539311 -0.3481360 -0.101564655  0.10391148
       15.2 -0.71225245 -0.52079367 -0.3440625 -0.123148524  0.06094645
       15.7 -0.66541659 -0.49619423 -0.3399890 -0.144732393  0.01798142
       16.2 -0.61858074 -0.47159478 -0.3359154 -0.166316263 -0.02498361
       16.7 -0.57174488 -0.44699534 -0.3318419 -0.187900132 -0.06794865
       17.1 -0.53427620 -0.42731579 -0.3285831 -0.205167227 -0.10232067
       17.6 -0.48744035 -0.40271634 -0.3245096 -0.226751097 -0.14528571
       18.1 -0.44060450 -0.37811690 -0.3204360 -0.248334966 -0.18825074
       18.6 -0.39376864 -0.35351745 -0.3163625 -0.269918835 -0.23121577
       19.1 -0.34693279 -0.32891801 -0.3122890 -0.291502704 -0.27418080
       19.6 -0.30009693 -0.30431857 -0.3082155 -0.313086574 -0.31714584
       20.1 -0.25326108 -0.27971912 -0.3041419 -0.334670443 -0.36011087
       20.6 -0.20642523 -0.25511968 -0.3000684 -0.356254312 -0.40307590
       21.1 -0.15958937 -0.23052024 -0.2959949 -0.377838182 -0.44604093
       21.6 -0.11275352 -0.20592079 -0.2919214 -0.399422051 -0.48900597
       22   -0.07528484 -0.18624124 -0.2886625 -0.416689146 -0.52337799
       22.5 -0.02844899 -0.16164180 -0.2845890 -0.438273016 -0.56634303
       23    0.01838687 -0.13704235 -0.2805155 -0.459856885 -0.60930806
       23.5  0.06522272 -0.11244291 -0.2764420 -0.481440754 -0.65227309
       24    0.11205858 -0.08784346 -0.2723684 -0.503024623 -0.69523812
> summary(eff.cowles[["neuroticism"]], type="link")

 neuroticism*extraversion effect
           extraversion
neuroticism           2         7.2         12           18          23
       0    -2.13606239 -1.26861675 -0.4678977  0.533001102  1.36708344
       0.49 -2.09016325 -1.24450930 -0.4639057  0.511848911  1.32497771
       0.98 -2.04426412 -1.22040184 -0.4599136  0.490696719  1.28287198
       1.47 -1.99836498 -1.19629439 -0.4559215  0.469544527  1.24076625
       1.96 -1.95246584 -1.17218694 -0.4519295  0.448392335  1.19866052
       2.45 -1.90656671 -1.14807948 -0.4479374  0.427240143  1.15655478
       2.94 -1.86066757 -1.12397203 -0.4439454  0.406087951  1.11444905
       3.43 -1.81476843 -1.09986457 -0.4399533  0.384935759  1.07234332
       3.92 -1.76886930 -1.07575712 -0.4359613  0.363783567  1.03023759
       4.41 -1.72297016 -1.05164966 -0.4319692  0.342631375  0.98813186
       4.9  -1.67707103 -1.02754221 -0.4279771  0.321479183  0.94602612
       5.39 -1.63117189 -1.00343475 -0.4239851  0.300326992  0.90392039
       5.88 -1.58527275 -0.97932730 -0.4199930  0.279174800  0.86181466
       6.37 -1.53937362 -0.95521984 -0.4160010  0.258022608  0.81970893
       6.86 -1.49347448 -0.93111239 -0.4120089  0.236870416  0.77760320
       7.35 -1.44757534 -0.90700493 -0.4080169  0.215718224  0.73549746
       7.84 -1.40167621 -0.88289748 -0.4040248  0.194566032  0.69339173
       8.33 -1.35577707 -0.85879002 -0.4000328  0.173413840  0.65128600
       8.82 -1.30987793 -0.83468257 -0.3960407  0.152261648  0.60918027
       9.31 -1.26397880 -0.81057512 -0.3920486  0.131109456  0.56707454
       9.8  -1.21807966 -0.78646766 -0.3880566  0.109957264  0.52496880
       10.3 -1.17124381 -0.76186822 -0.3839831  0.088373395  0.48200377
       10.8 -1.12440796 -0.73726877 -0.3799095  0.066789526  0.43903874
       11.3 -1.07757210 -0.71266933 -0.3758360  0.045205657  0.39607371
       11.8 -1.03073625 -0.68806989 -0.3717625  0.023621787  0.35310867
       12.2 -0.99326757 -0.66839033 -0.3685037  0.006354692  0.31873665
       12.7 -0.94643171 -0.64379089 -0.3644301 -0.015229177  0.27577161
       13.2 -0.89959586 -0.61919144 -0.3603566 -0.036813047  0.23280658
       13.7 -0.85276001 -0.59459200 -0.3562831 -0.058396916  0.18984155
       14.2 -0.80592415 -0.56999256 -0.3522095 -0.079980785  0.14687652
       14.7 -0.75908830 -0.54539311 -0.3481360 -0.101564655  0.10391148
       15.2 -0.71225245 -0.52079367 -0.3440625 -0.123148524  0.06094645
       15.7 -0.66541659 -0.49619423 -0.3399890 -0.144732393  0.01798142
       16.2 -0.61858074 -0.47159478 -0.3359154 -0.166316263 -0.02498361
       16.7 -0.57174488 -0.44699534 -0.3318419 -0.187900132 -0.06794865
       17.1 -0.53427620 -0.42731579 -0.3285831 -0.205167227 -0.10232067
       17.6 -0.48744035 -0.40271634 -0.3245096 -0.226751097 -0.14528571
       18.1 -0.44060450 -0.37811690 -0.3204360 -0.248334966 -0.18825074
       18.6 -0.39376864 -0.35351745 -0.3163625 -0.269918835 -0.23121577
       19.1 -0.34693279 -0.32891801 -0.3122890 -0.291502704 -0.27418080
       19.6 -0.30009693 -0.30431857 -0.3082155 -0.313086574 -0.31714584
       20.1 -0.25326108 -0.27971912 -0.3041419 -0.334670443 -0.36011087
       20.6 -0.20642523 -0.25511968 -0.3000684 -0.356254312 -0.40307590
       21.1 -0.15958937 -0.23052024 -0.2959949 -0.377838182 -0.44604093
       21.6 -0.11275352 -0.20592079 -0.2919214 -0.399422051 -0.48900597
       22   -0.07528484 -0.18624124 -0.2886625 -0.416689146 -0.52337799
       22.5 -0.02844899 -0.16164180 -0.2845890 -0.438273016 -0.56634303
       23    0.01838687 -0.13704235 -0.2805155 -0.459856885 -0.60930806
       23.5  0.06522272 -0.11244291 -0.2764420 -0.481440754 -0.65227309
       24    0.11205858 -0.08784346 -0.2723684 -0.503024623 -0.69523812

 Lower 95 Percent Confidence Limits
           extraversion
neuroticism          2        7.2         12           18           23
       0    -2.9715009 -1.7591713 -0.7522189  0.047997939  0.551931357
       0.49 -2.8971111 -1.7184850 -0.7380889  0.044904721  0.539528611
       0.98 -2.8229001 -1.6779003 -0.7240288  0.041679537  0.526914474
       1.47 -2.7488880 -1.6374287 -0.7100467  0.038305929  0.514063208
       1.96 -2.6750982 -1.5970831 -0.6961523  0.034764757  0.500944986
       2.45 -2.6015574 -1.5568786 -0.6823568  0.031033676  0.487525107
       2.94 -2.5282965 -1.5168326 -0.6686730  0.027086498  0.473763050
       3.43 -2.4553514 -1.4769651 -0.6551161  0.022892414  0.459611329
       3.92 -2.3827637 -1.4372995 -0.6417036  0.018415050  0.445014102
       4.41 -2.3105823 -1.3978630 -0.6284566  0.013611335  0.429905504
       4.9  -2.2388642 -1.3586874 -0.6153993  0.008430134  0.414207652
       5.39 -2.1676761 -1.3198101 -0.6025608  0.002810650  0.397828295
       5.88 -2.0970968 -1.2812747 -0.5899752 -0.003319423  0.380658106
       6.37 -2.0272185 -1.2431327 -0.5776828 -0.010045936  0.362567654
       6.86 -1.9581500 -1.2054445 -0.5657311 -0.017470395  0.343404215
       7.35 -1.8900182 -1.1682808 -0.5541758 -0.025711885  0.322988722
       7.84 -1.8229717 -1.1317243 -0.5430816 -0.034908353  0.301113433
       8.33 -1.7571820 -1.0958705 -0.5325227 -0.045216521  0.277541217
       8.82 -1.6928449 -1.0608291 -0.5225824 -0.056809446  0.252007822
       9.31 -1.6301800 -1.0267233 -0.5133518 -0.069870532  0.224228730
       9.8  -1.5694266 -0.9936886 -0.5049264 -0.084583053  0.193912265
       10.3 -1.5096650 -0.9612332 -0.4972570 -0.101472424  0.160072401
       10.8 -1.4524223 -0.9301974 -0.4906156 -0.120398777  0.123046315
       11.3 -1.3979438 -0.9007271 -0.4850748 -0.141449138  0.082652831
       11.8 -1.3464306 -0.8729460 -0.4806791 -0.164641566  0.038809282
       12.2 -1.3074468 -0.8519980 -0.4779950 -0.184703862  0.001265864
       12.7 -1.2615473 -0.8274477 -0.4756615 -0.211573251 -0.048643570
       13.2 -1.2187624 -0.8047098 -0.4744133 -0.240285761 -0.101667267
       13.7 -1.1789761 -0.7837308 -0.4741722 -0.270655771 -0.157534800
       14.2 -1.1419997 -0.7644125 -0.4748440 -0.302487018 -0.215942900
       14.7 -1.1075949 -0.7466242 -0.4763272 -0.335587627 -0.276582353
       15.2 -1.0754977 -0.7302166 -0.4785214 -0.369779839 -0.339157559
       15.7 -1.0454398 -0.7150348 -0.4813319 -0.404905000 -0.403398347
       16.2 -1.0171636 -0.7009278 -0.4846732 -0.440825080 -0.469065391
       16.7 -0.9904324 -0.6877551 -0.4884700 -0.477422018 -0.535951179
       17.1 -0.9700166 -0.6778041 -0.4917912 -0.507119221 -0.590217166
       17.6 -0.9455505 -0.6660044 -0.4962499 -0.544693520 -0.658868013
       18.1 -0.9221026 -0.6548225 -0.5010046 -0.582703458 -0.728306859
       18.6 -0.8995315 -0.6441729 -0.5060141 -0.621087910 -0.798423379
       19.1 -0.8777171 -0.6339826 -0.5112434 -0.659795624 -0.869124797
       19.6 -0.8565573 -0.6241895 -0.5166631 -0.698783549 -0.940333023
       20.1 -0.8359655 -0.6147409 -0.5222483 -0.738015413 -1.011982185
       20.6 -0.8158683 -0.6055922 -0.5279780 -0.777460554 -1.084016563
       21.1 -0.7962036 -0.5967054 -0.5338343 -0.817092957 -1.156388867
       21.6 -0.7769181 -0.5880483 -0.5398021 -0.856890458 -1.229058814
       22   -0.7617321 -0.5812692 -0.5446477 -0.888834495 -1.287385756
       22.5 -0.7430196 -0.5729585 -0.5507845 -0.928883210 -1.360507960
       23   -0.7245752 -0.5648098 -0.5570007 -0.969050385 -1.433843112
       23.5 -0.7063694 -0.5568051 -0.5632878 -1.009323511 -1.507368521
       24   -0.6883765 -0.5489288 -0.5696384 -1.049691720 -1.581064497

 Upper 95 Percent Confidence Limits
           extraversion
neuroticism           2         7.2           12         18        23
       0    -1.30062392 -0.77806217 -0.183576477 1.01800427 2.1822355
       0.49 -1.28321543 -0.77053358 -0.189722357 0.97879310 2.1104268
       0.98 -1.26562818 -0.76290335 -0.195798419 0.93971390 2.0388295
       1.47 -1.24784192 -0.75516011 -0.201796368 0.90078312 1.9674693
       1.96 -1.22983344 -0.74729079 -0.207706615 0.86201991 1.8963760
       2.45 -1.21157599 -0.73928036 -0.213518048 0.82344661 1.8255845
       2.94 -1.19303863 -0.73111148 -0.219217734 0.78508940 1.7551351
       3.43 -1.17418550 -0.72276407 -0.224790571 0.74697910 1.6850753
       3.92 -1.15497486 -0.71421476 -0.230218868 0.70915208 1.6154611
       4.41 -1.13535799 -0.70543634 -0.235481834 0.67165142 1.5463582
       4.9  -1.11527789 -0.69639700 -0.240554975 0.63452823 1.4778446
       5.39 -1.09466766 -0.68705945 -0.245409380 0.59784333 1.4100125
       5.88 -1.07344873 -0.67737992 -0.250010894 0.56166902 1.3429712
       6.37 -1.05152869 -0.66730699 -0.254319188 0.52609115 1.2768502
       6.86 -1.02879900 -0.65678030 -0.258286756 0.49121123 1.2118022
       7.35 -1.00513244 -0.64572906 -0.261857921 0.45714833 1.1480062
       7.84 -0.98038067 -0.63407069 -0.264967988 0.42404042 1.0856700
       8.33 -0.95437213 -0.62170953 -0.267542785 0.39204420 1.0250308
       8.82 -0.92691094 -0.60853605 -0.269498952 0.36133274 0.9663527
       9.31 -0.89777763 -0.59442693 -0.270745447 0.33208944 0.9099203
       9.8  -0.86673272 -0.57924670 -0.271186803 0.30449758 0.8560253
       10.3 -0.83282259 -0.56250324 -0.270709146 0.27821921 0.8039351
       10.8 -0.79639365 -0.54434013 -0.269203443 0.25397783 0.7550312
       11.3 -0.75720037 -0.52461155 -0.266597171 0.23186045 0.7094946
       11.8 -0.71504190 -0.50319373 -0.262845844 0.21188514 0.6674081
       12.2 -0.67908837 -0.48478262 -0.259012341 0.19741325 0.6362074
       12.7 -0.63131616 -0.46013408 -0.253198727 0.18111490 0.6001868
       13.2 -0.58042934 -0.43367311 -0.246299918 0.16665967 0.5672804
       13.7 -0.52654394 -0.40545321 -0.238393909 0.15386194 0.5372179
       14.2 -0.46984859 -0.37557262 -0.229575094 0.14252545 0.5096959
       14.7 -0.41058169 -0.34416204 -0.219944801 0.13245832 0.4844053
       15.2 -0.34900716 -0.31137071 -0.209603600 0.12348279 0.4610505
       15.7 -0.28539341 -0.27735362 -0.198646032 0.11544021 0.4393612
       16.2 -0.21999786 -0.24226174 -0.187157643 0.10819255 0.4190982
       16.7 -0.15305740 -0.20623555 -0.175213803 0.10162175 0.4000539
       17.1 -0.09853583 -0.17682744 -0.165374950 0.09678477 0.3855758
       17.6 -0.02933016 -0.13942828 -0.152769219 0.09119133 0.3682966
       18.1  0.04089360 -0.10141128 -0.139867433 0.08603353 0.3518054
       18.6  0.11199425 -0.06286199 -0.126710932 0.08125024 0.3359918
       19.1  0.18385153 -0.02385343 -0.113334599 0.07679022 0.3207632
       19.6  0.25636339  0.01555234 -0.099767864 0.07261040 0.3060414
       20.1  0.32944330  0.05530266 -0.086035587 0.06867453 0.2917604
       20.6  0.40301788  0.09535285 -0.072158816 0.06495193 0.2778648
       21.1  0.47702481  0.13566495 -0.058155416 0.06141659 0.2643070
       21.6  0.55141102  0.17620667 -0.044040604 0.05804636 0.2510469
       22    0.61116241  0.20878669 -0.032677345 0.05545620 0.2406298
       22.5  0.68612160  0.24967490 -0.018393518 0.05233718 0.2278219
       23    0.76134893  0.29072509 -0.004030245 0.04933662 0.2152270
       23.5  0.83681480  0.33191928  0.010403925 0.04644200 0.2028223
       24    0.91249361  0.37324190  0.024901579 0.04364247 0.1905883
> as.data.frame(eff.cowles)
$sex
     sex       fit         se     lower     upper
1 female 0.4409440 0.01815204 0.4057279 0.4767645
2   male 0.3811939 0.01967564 0.3434476 0.4204322

$neuroticism
    neuroticism extraversion       fit         se      lower     upper
1          0.00          2.0 0.1056408 0.04027265 0.04873010 0.2140600
2          0.49          2.0 0.1100566 0.04032513 0.05229656 0.2170034
3          0.98          2.0 0.1146332 0.04031997 0.05609917 0.2200066
4          1.47          2.0 0.1193747 0.04025496 0.06014948 0.2230739
5          1.96          2.0 0.1242847 0.04012823 0.06445884 0.2262106
6          2.45          2.0 0.1293671 0.03993831 0.06903825 0.2294223
7          2.94          2.0 0.1346253 0.03968422 0.07389814 0.2327159
8          3.43          2.0 0.1400628 0.03936560 0.07904809 0.2360993
9          3.92          2.0 0.1456830 0.03898285 0.08449653 0.2395816
10         4.41          2.0 0.1514890 0.03853729 0.09025032 0.2431737
11         4.90          2.0 0.1574837 0.03803140 0.09631436 0.2468882
12         5.39          2.0 0.1636699 0.03746895 0.10269097 0.2507403
13         5.88          2.0 0.1700500 0.03685541 0.10937932 0.2547478
14         6.37          2.0 0.1766264 0.03619813 0.11637464 0.2589317
15         6.86          2.0 0.1834008 0.03550682 0.12366740 0.2633170
16         7.35          2.0 0.1903750 0.03479389 0.13124239 0.2679335
17         7.84          2.0 0.1975503 0.03407487 0.13907767 0.2728163
18         8.33          2.0 0.2049275 0.03336888 0.14714362 0.2780064
19         8.82          2.0 0.2125073 0.03269893 0.15540207 0.2835518
20         9.31          2.0 0.2202897 0.03209217 0.16380571 0.2895074
21         9.80          2.0 0.2282746 0.03157973 0.17229815 0.2959346
22        10.30          2.0 0.2366302 0.03118995 0.18098844 0.3030486
23        10.80          2.0 0.2451946 0.03097352 0.18962906 0.3107975
24        11.30          2.0 0.2539657 0.03096992 0.19814260 0.3192544
25        11.80          2.0 0.2629414 0.03121618 0.20645454 0.3284857
26        12.20          2.0 0.2702672 0.03161451 0.21291441 0.3364648
27        12.70          2.0 0.2796030 0.03238437 0.22070765 0.3472122
28        13.20          2.0 0.2891336 0.03347000 0.22815432 0.3588338
29        13.70          2.0 0.2988542 0.03487586 0.23523635 0.3713233
30        14.20          2.0 0.3087597 0.03659641 0.24195340 0.3846521
31        14.70          2.0 0.3188442 0.03861784 0.24831954 0.3987727
32        15.20          2.0 0.3291013 0.04092027 0.25435898 0.4136232
33        15.70          2.0 0.3395239 0.04347999 0.26010175 0.4291320
34        16.20          2.0 0.3501043 0.04627130 0.26558026 0.4452213
35        16.70          2.0 0.3608343 0.04926780 0.27082669 0.4618102
36        17.10          2.0 0.3695201 0.05179514 0.27487720 0.4753860
37        17.60          2.0 0.3804967 0.05509553 0.27978052 0.4926680
38        18.10          2.0 0.3915969 0.05852982 0.28452967 0.5102220
39        18.60          2.0 0.4028104 0.06207429 0.28914678 0.5279693
40        19.10          2.0 0.4141264 0.06570627 0.29365107 0.5458339
41        19.60          2.0 0.4255338 0.06940402 0.29805914 0.5637421
42        20.10          2.0 0.4370210 0.07314669 0.30238518 0.5816239
43        20.60          2.0 0.4485762 0.07691425 0.30664140 0.5994125
44        21.10          2.0 0.4601871 0.08068744 0.31083820 0.6170451
45        21.60          2.0 0.4718414 0.08444773 0.31498449 0.6344629
46        22.00          2.0 0.4811877 0.08743471 0.31827033 0.6482059
47        22.50          2.0 0.4928882 0.09112744 0.32234420 0.6651036
48        23.00          2.0 0.5045966 0.09475930 0.32638629 0.6816465
49        23.50          2.0 0.5162999 0.09831457 0.33040158 0.6977940
50        24.00          2.0 0.5279854 0.10177834 0.33439434 0.7135102
51         0.00          7.2 0.2194941 0.04287838 0.14689415 0.3147377
52         0.49          7.2 0.2236521 0.04198917 0.15206641 0.3163637
53         0.98          7.2 0.2278657 0.04106893 0.15737370 0.3180162
54         1.47          7.2 0.2321351 0.04011884 0.16281525 0.3196980
55         1.96          7.2 0.2364599 0.03914029 0.16838969 0.3214119
56         2.45          7.2 0.2408400 0.03813501 0.17409500 0.3231615
57         2.94          7.2 0.2452753 0.03710502 0.17992841 0.3249509
58         3.43          7.2 0.2497653 0.03605274 0.18588626 0.3267846
59         3.92          7.2 0.2543098 0.03498103 0.19196389 0.3286682
60         4.41          7.2 0.2589084 0.03389329 0.19815544 0.3306080
61         4.90          7.2 0.2635609 0.03279353 0.20445371 0.3326115
62         5.39          7.2 0.2682666 0.03168648 0.21084990 0.3346875
63         5.88          7.2 0.2730253 0.03057774 0.21733332 0.3368463
64         6.37          7.2 0.2778363 0.02947390 0.22389117 0.3391001
65         6.86          7.2 0.2826991 0.02838274 0.23050809 0.3414632
66         7.35          7.2 0.2876131 0.02731340 0.23716588 0.3439526
67         7.84          7.2 0.2925777 0.02627659 0.24384303 0.3465881
68         8.33          7.2 0.2975922 0.02528475 0.25051443 0.3493927
69         8.82          7.2 0.3026559 0.02435219 0.25715105 0.3523932
70         9.31          7.2 0.3077680 0.02349517 0.26371985 0.3556198
71         9.80          7.2 0.3129276 0.02273170 0.27018412 0.3591059
72        10.30          7.2 0.3182408 0.02206925 0.27663136 0.3629685
73        10.80          7.2 0.3236017 0.02154576 0.28288467 0.3671785
74        11.30          7.2 0.3290093 0.02118204 0.28890110 0.3717745
75        11.80          7.2 0.3344626 0.02099679 0.29464166 0.3767904
76        12.20          7.2 0.3388574 0.02098722 0.29901389 0.3811234
77        12.70          7.2 0.3443901 0.02115705 0.30418501 0.3869540
78        13.20          7.2 0.3499654 0.02153279 0.30901895 0.3932496
79        13.70          7.2 0.3555819 0.02211260 0.31351637 0.4000029
80        14.20          7.2 0.3612385 0.02288893 0.31768903 0.4071952
81        14.70          7.2 0.3669339 0.02384975 0.32155732 0.4147988
82        15.20          7.2 0.3726667 0.02498015 0.32514719 0.4227802
83        15.70          7.2 0.3784355 0.02626382 0.32848728 0.4311027
84        16.20          7.2 0.3842388 0.02768421 0.33160655 0.4397291
85        16.70          7.2 0.3900754 0.02922541 0.33453264 0.4486231
86        17.10          7.2 0.3947675 0.03053536 0.33675157 0.4559080
87        17.60          7.2 0.4006599 0.03225762 0.33939210 0.4651993
88        18.10          7.2 0.4065812 0.03406265 0.34190362 0.4746689
89        18.60          7.2 0.4125297 0.03593946 0.34430386 0.4842897
90        19.10          7.2 0.4185039 0.03787826 0.34660805 0.4940369
91        19.60          7.2 0.4245021 0.03987037 0.34882922 0.5038880
92        20.10          7.2 0.4305226 0.04190805 0.35097849 0.5138221
93        20.60          7.2 0.4365638 0.04398437 0.35306533 0.5238202
94        21.10          7.2 0.4426238 0.04609309 0.35509780 0.5338643
95        21.60          7.2 0.4487009 0.04822857 0.35708280 0.5439380
96        22.00          7.2 0.4535738 0.04995272 0.35864061 0.5520079
97        22.50          7.2 0.4596773 0.05212361 0.36055445 0.5620965
98        23.00          7.2 0.4657929 0.05430779 0.36243530 0.5721736
99        23.50          7.2 0.4719189 0.05650111 0.36428702 0.5822263
100       24.00          7.2 0.4780532 0.05869968 0.36611296 0.5922421
101        0.00         12.0 0.3851139 0.03435145 0.32033800 0.4542343
102        0.49         12.0 0.3860597 0.03315687 0.32342218 0.4527112
103        0.98         12.0 0.3870063 0.03196828 0.32650644 0.4512062
104        1.47         12.0 0.3879538 0.03078675 0.32958852 0.4497214
105        1.96         12.0 0.3889021 0.02961347 0.33266585 0.4482592
106        2.45         12.0 0.3898513 0.02844986 0.33573549 0.4468224
107        2.94         12.0 0.3908013 0.02729753 0.33879404 0.4454140
108        3.43         12.0 0.3917521 0.02615839 0.34183757 0.4440378
109        3.92         12.0 0.3927037 0.02503464 0.34486153 0.4426981
110        4.41         12.0 0.3936562 0.02392889 0.34786059 0.4414001
111        4.90         12.0 0.3946095 0.02284420 0.35082853 0.4401496
112        5.39         12.0 0.3955635 0.02178418 0.35375804 0.4389537
113        5.88         12.0 0.3965184 0.02075308 0.35664055 0.4378208
114        6.37         12.0 0.3974741 0.01975593 0.35946596 0.4367607
115        6.86         12.0 0.3984305 0.01879866 0.36222244 0.4357849
116        7.35         12.0 0.3993877 0.01788818 0.36489613 0.4349070
117        7.84         12.0 0.4003457 0.01703258 0.36747101 0.4341429
118        8.33         12.0 0.4013045 0.01624108 0.36992870 0.4335104
119        8.82         12.0 0.4022640 0.01552410 0.37224857 0.4330301
120        9.31         12.0 0.4032242 0.01489299 0.37440811 0.4327241
121        9.80         12.0 0.4041852 0.01435972 0.37638366 0.4326158
122       10.30         12.0 0.4051666 0.01392871 0.37818551 0.4327330
123       10.80         12.0 0.4061487 0.01362342 0.37974855 0.4331027
124       11.30         12.0 0.4071316 0.01345309 0.38105450 0.4337427
125       11.80         12.0 0.4081152 0.01342351 0.38209178 0.4346643
126       12.20         12.0 0.4089026 0.01350239 0.38272570 0.4356065
127       12.70         12.0 0.4098876 0.01372710 0.38327711 0.4370363
128       13.20         12.0 0.4108732 0.01408605 0.38357221 0.4387344
129       13.70         12.0 0.4118596 0.01456988 0.38362921 0.4406822
130       14.20         12.0 0.4128467 0.01516718 0.38347038 0.4428570
131       14.70         12.0 0.4138345 0.01586562 0.38311977 0.4452344
132       15.20         12.0 0.4148230 0.01665296 0.38260134 0.4477901
133       15.70         12.0 0.4158122 0.01751764 0.38193766 0.4505012
134       16.20         12.0 0.4168020 0.01844920 0.38114922 0.4533467
135       16.70         12.0 0.4177925 0.01943838 0.38025406 0.4563083
136       17.10         12.0 0.4185854 0.02026580 0.37947169 0.4587502
137       17.60         12.0 0.4195771 0.02133932 0.37842236 0.4618818
138       18.10         12.0 0.4205695 0.02245088 0.37730460 0.4650900
139       18.60         12.0 0.4215625 0.02359537 0.37612838 0.4683646
140       19.10         12.0 0.4225561 0.02476849 0.37490210 0.4716966
141       19.60         12.0 0.4235504 0.02596661 0.37363285 0.4750787
142       20.10         12.0 0.4245453 0.02718663 0.37232666 0.4785044
143       20.60         12.0 0.4255408 0.02842594 0.37098861 0.4819681
144       21.10         12.0 0.4265369 0.02968232 0.36962303 0.4854652
145       21.60         12.0 0.4275336 0.03095387 0.36823362 0.4889916
146       22.00         12.0 0.4283313 0.03198092 0.36710707 0.4918314
147       22.50         12.0 0.4293291 0.03327581 0.36568242 0.4954018
148       23.00         12.0 0.4303274 0.03458185 0.36424172 0.4989924
149       23.50         12.0 0.4313263 0.03589795 0.36278706 0.5026010
150       24.00         12.0 0.4323257 0.03722316 0.36132026 0.5062251
151        0.00         18.0 0.6301828 0.05767002 0.51199718 0.7345837
152        0.49         18.0 0.6252398 0.05582349 0.51122429 0.7268687
153        0.98         18.0 0.6202705 0.05395980 0.51041838 0.7190419
154        1.47         18.0 0.6152759 0.05208214 0.50957531 0.7111104
155        1.96         18.0 0.6102569 0.05019408 0.50869031 0.7030825
156        2.45         18.0 0.6052144 0.04829965 0.50775780 0.6949675
157        2.94         18.0 0.6001495 0.04640341 0.50677121 0.6867760
158        3.43         18.0 0.5950630 0.04451054 0.50572285 0.6785201
159        3.92         18.0 0.5899560 0.04262700 0.50460363 0.6702138
160        4.41         18.0 0.5848296 0.04075961 0.50340278 0.6618728
161        4.90         18.0 0.5796847 0.03891628 0.50210752 0.6535155
162        5.39         18.0 0.5745225 0.03710619 0.50070266 0.6451627
163        5.88         18.0 0.5693439 0.03534002 0.49917015 0.6368386
164        6.37         18.0 0.5641501 0.03363019 0.49748854 0.6285710
165        6.86         18.0 0.5589423 0.03199119 0.49563251 0.6203917
166        7.35         18.0 0.5537214 0.03043972 0.49357238 0.6123375
167        7.84         18.0 0.5484886 0.02899496 0.49127380 0.6044497
168        8.33         18.0 0.5432451 0.02767843 0.48869780 0.5967747
169        8.82         18.0 0.5379920 0.02651375 0.48580146 0.5893630
170        9.31         18.0 0.5327305 0.02552582 0.48253947 0.5822677
171        9.80         18.0 0.5274617 0.02473942 0.47886683 0.5755416
172       10.30         18.0 0.5220790 0.02416825 0.47465364 0.5691096
173       10.80         18.0 0.5166912 0.02384989 0.46993661 0.5631553
174       11.30         18.0 0.5112995 0.02379629 0.46469656 0.5577068
175       11.80         18.0 0.5059052 0.02401027 0.45893233 0.5527740
176       12.20         18.0 0.5015887 0.02436992 0.45395486 0.5491937
177       12.70         18.0 0.4961928 0.02504290 0.44730311 0.5451554
178       13.20         18.0 0.4907978 0.02594484 0.44021593 0.5415687
179       13.70         18.0 0.4854049 0.02705126 0.43274611 0.5383898
180       14.20         18.0 0.4800155 0.02833608 0.42494962 0.5355712
181       14.70         18.0 0.4746306 0.02977357 0.41688169 0.5330662
182       15.20         18.0 0.4692517 0.03133968 0.40859422 0.5308315
183       15.70         18.0 0.4638799 0.03301271 0.40013443 0.5288280
184       16.20         18.0 0.4585165 0.03477350 0.39154439 0.5270218
185       16.70         18.0 0.4531627 0.03660544 0.38286106 0.5253836
186       17.10         18.0 0.4488874 0.03811251 0.37586909 0.5241773
187       17.60         18.0 0.4435539 0.04003777 0.36709643 0.5227820
188       18.10         18.0 0.4382334 0.04199897 0.35831077 0.5214951
189       18.60         18.0 0.4329270 0.04398674 0.34953406 0.5203014
190       19.10         18.0 0.4276360 0.04599301 0.34078552 0.5191881
191       19.60         18.0 0.4223615 0.04801076 0.33208199 0.5181446
192       20.10         18.0 0.4171047 0.05003388 0.32343827 0.5171619
193       20.60         18.0 0.4118666 0.05205700 0.31486745 0.5162323
194       21.10         18.0 0.4066484 0.05407538 0.30638109 0.5153493
195       21.60         18.0 0.4014512 0.05608482 0.29798943 0.5145075
196       22.00         18.0 0.3973093 0.05768340 0.29135041 0.5138605
197       22.50         18.0 0.3921526 0.05966754 0.28315134 0.5130813
198       23.00         18.0 0.3870198 0.06163315 0.27506982 0.5123317
199       23.50         18.0 0.3819120 0.06357743 0.26711226 0.5116084
200       24.00         18.0 0.3768301 0.06549783 0.25928430 0.5109089
201        0.00         23.0 0.7969085 0.06731172 0.63458356 0.8986429
202        0.49         23.0 0.7900087 0.06648186 0.63170275 0.8919125
203        0.98         23.0 0.7829383 0.06554810 0.62876317 0.8848140
204        1.47         23.0 0.7756974 0.06451127 0.62575850 0.8773390
205        1.96         23.0 0.7682864 0.06337310 0.62268138 0.8694808
206        2.45         23.0 0.7607061 0.06213635 0.61952324 0.8612349
207        2.94         23.0 0.7529576 0.06080498 0.61627403 0.8525993
208        3.43         23.0 0.7450423 0.05938429 0.61292197 0.8435754
209        3.92         23.0 0.7369620 0.05788117 0.60945314 0.8341682
210        4.41         23.0 0.7287188 0.05630435 0.60585110 0.8243871
211        4.90         23.0 0.7203153 0.05466466 0.60209636 0.8142468
212        5.39         23.0 0.7117545 0.05297540 0.59816577 0.8037679
213        5.88         23.0 0.7030396 0.05125268 0.59403182 0.7929781
214        6.37         23.0 0.6941746 0.04951590 0.58966185 0.7819131
215        6.86         23.0 0.6851633 0.04778814 0.58501721 0.7706177
216        7.35         23.0 0.6760105 0.04609666 0.58005245 0.7591466
217        7.84         23.0 0.6667210 0.04447319 0.57471468 0.7475655
218        8.33         23.0 0.6573002 0.04295410 0.56894332 0.7359514
219        8.82         23.0 0.6477538 0.04158016 0.56267063 0.7243919
220        9.31         23.0 0.6380879 0.04039563 0.55582348 0.7129839
221        9.80         23.0 0.6283089 0.03944659 0.54832673 0.7018296
222       10.30         23.0 0.6182209 0.03876779 0.53993287 0.6908156
223       10.80         23.0 0.6080300 0.03842434 0.53072283 0.6802740
224       11.30         23.0 0.5977440 0.03845011 0.52065145 0.6702895
225       11.80         23.0 0.5873712 0.03886580 0.50970110 0.6609225
226       12.20         23.0 0.5790163 0.03948314 0.50031647 0.6538956
227       12.70         23.0 0.5685093 0.04060337 0.48784150 0.6456990
228       13.20         23.0 0.5579402 0.04209037 0.47460505 0.6381354
229       13.70         23.0 0.5473184 0.04391219 0.46069755 0.6311650
230       14.20         23.0 0.5366533 0.04603014 0.44622309 0.6247352
231       14.70         23.0 0.5259545 0.04840249 0.43129186 0.6187876
232       15.20         23.0 0.5152319 0.05098725 0.41601413 0.6132633
233       15.70         23.0 0.5044952 0.05374406 0.40049612 0.6081068
234       16.20         23.0 0.4937544 0.05663529 0.38483748 0.6032674
235       16.70         23.0 0.4830194 0.05962645 0.36912994 0.5987006
236       17.10         23.0 0.4744421 0.06207024 0.35658503 0.5952172
237       17.60         23.0 0.4637423 0.06516467 0.34099394 0.5910473
238       18.10         23.0 0.4530758 0.06827926 0.32556639 0.5870553
239       18.60         23.0 0.4424522 0.07139083 0.31036287 0.5832166
240       19.10         23.0 0.4318810 0.07447858 0.29543645 0.5795102
241       19.60         23.0 0.4213715 0.07752386 0.28083308 0.5759187
242       20.10         23.0 0.4109327 0.08050992 0.26659211 0.5724271
243       20.60         23.0 0.4005735 0.08342176 0.25274667 0.5690227
244       21.10         23.0 0.3903025 0.08624596 0.23932407 0.5656948
245       21.60         23.0 0.3801278 0.08897058 0.22634620 0.5624342
246       22.00         23.0 0.3720627 0.09107142 0.21629563 0.5598688
247       22.50         23.0 0.3620811 0.09359097 0.20415776 0.5567104
248       23.00         23.0 0.3522171 0.09598446 0.19250059 0.5536000
249       23.50         23.0 0.3424775 0.09824470 0.18132911 0.5505325
250       24.00         23.0 0.3328688 0.10036560 0.17064478 0.5475034

$extraversion
    extraversion neuroticism       fit         se      lower     upper
1           2.00           0 0.1056408 0.04027265 0.04873010 0.2140600
2           2.43           0 0.1126123 0.04107243 0.05366203 0.2211860
3           2.86           0 0.1199820 0.04179568 0.05905367 0.2285069
4           3.29           0 0.1277647 0.04243279 0.06493951 0.2360275
5           3.71           0 0.1357783 0.04296277 0.07119935 0.2435707
6           4.14           0 0.1444174 0.04340176 0.07816620 0.2515010
7           4.57           0 0.1535085 0.04372715 0.08573270 0.2596479
8           5.00           0 0.1630629 0.04393088 0.09393340 0.2680185
9           5.43           0 0.1730903 0.04400598 0.10280109 0.2766216
10          5.86           0 0.1835991 0.04394695 0.11236581 0.2854672
11          6.29           0 0.1945958 0.04375021 0.12265361 0.2945677
12          6.71           0 0.2058120 0.04342399 0.13342002 0.3037167
13          7.14           0 0.2177842 0.04295452 0.14519110 0.3133671
14          7.57           0 0.2302510 0.04235343 0.15772395 0.3233261
15          8.00           0 0.2432094 0.04163058 0.17101223 0.3336201
16          8.43           0 0.2566540 0.04080104 0.18503610 0.3442815
17          8.86           0 0.2705761 0.03988598 0.19975984 0.3553494
18          9.29           0 0.2849639 0.03891351 0.21512931 0.3668717
19          9.71           0 0.2994523 0.03794244 0.23069329 0.3786190
20         10.10           0 0.3132758 0.03705768 0.24555519 0.3900178
21         10.60           0 0.3314929 0.03601006 0.26504147 0.4054147
22         11.00           0 0.3464424 0.03529843 0.28084609 0.4184451
23         11.40           0 0.3617013 0.03475282 0.29670956 0.4321808
24         11.90           0 0.3811714 0.03437839 0.31642826 0.4504324
25         12.30           0 0.3970307 0.03437701 0.33196746 0.4659514
26         12.70           0 0.4131094 0.03467493 0.34718455 0.4823038
27         13.10           0 0.4293755 0.03528824 0.36200180 0.4994718
28         13.60           0 0.4499206 0.03649596 0.37989032 0.5219936
29         14.00           0 0.4664841 0.03779235 0.39367542 0.5407492
30         14.40           0 0.4831219 0.03934720 0.40700357 0.5600315
31         14.90           0 0.5039674 0.04158992 0.42306361 0.5846640
32         15.30           0 0.5206374 0.04356637 0.43547671 0.6046154
33         15.70           0 0.5372616 0.04565299 0.44754659 0.6246271
34         16.10           0 0.5538033 0.04780341 0.45931206 0.6445601
35         16.60           0 0.5743100 0.05051543 0.47364425 0.6691707
36         17.00           0 0.5905367 0.05265658 0.48484724 0.6884749
37         17.40           0 0.6065686 0.05473492 0.49584412 0.7073289
38         17.90           0 0.6262867 0.05719909 0.50933154 0.7301352
39         18.30           0 0.6417680 0.05903262 0.51993440 0.7476866
40         18.70           0 0.6569592 0.06072095 0.53038483 0.7645621
41         19.10           0 0.6718357 0.06224728 0.54069260 0.7807200
42         19.60           0 0.6899547 0.06390772 0.55338788 0.7998643
43         20.00           0 0.7040448 0.06502677 0.56339904 0.8143156
44         20.40           0 0.7177566 0.06595335 0.57328525 0.8279907
45         20.90           0 0.7343427 0.06683683 0.58547079 0.8439958
46         21.30           0 0.7471549 0.06732387 0.59508297 0.8559402
47         21.70           0 0.7595515 0.06761827 0.60457453 0.8671373
48         22.10           0 0.7715261 0.06772465 0.61394526 0.8776080
49         22.60           0 0.7858950 0.06760302 0.62548769 0.8897124
50         23.00           0 0.7969085 0.06731172 0.63458356 0.8986429
51          2.00           6 0.1716423 0.03669815 0.11106435 0.2557552
52          2.43           6 0.1788194 0.03656152 0.11791073 0.2618515
53          2.86           6 0.1862292 0.03635652 0.12511070 0.2680570
54          3.29           6 0.1938735 0.03608123 0.13267355 0.2743733
55          3.71           6 0.2015678 0.03574304 0.14041879 0.2806514
56          4.14           6 0.2096795 0.03532481 0.14872214 0.2871926
57          4.57           6 0.2180284 0.03483325 0.15740911 0.2938512
58          5.00           6 0.2266145 0.03426854 0.16648347 0.3006306
59          5.43           6 0.2354369 0.03363158 0.17594697 0.3075346
60          5.86           6 0.2444942 0.03292421 0.18579887 0.3145681
61          6.29           6 0.2537843 0.03214926 0.19603565 0.3217368
62          6.71           6 0.2630804 0.03133100 0.20639940 0.3288764
63          7.14           6 0.2728216 0.03043583 0.21737329 0.3363356
64          7.57           6 0.2827852 0.02948961 0.22870009 0.3439570
65          8.00           6 0.2929660 0.02850141 0.24035994 0.3517543
66          8.43           6 0.3033583 0.02748254 0.25232723 0.3597443
67          8.86           6 0.3139556 0.02644700 0.26456977 0.3679479
68          9.29           6 0.3247505 0.02541181 0.27704794 0.3763904
69          9.71           6 0.3354774 0.02442067 0.28941756 0.3848970
70         10.10           6 0.3455928 0.02353782 0.30101795 0.3930566
71         10.60           6 0.3587675 0.02249308 0.31597100 0.4039374
72         11.00           6 0.3694640 0.02175846 0.32792668 0.4130292
73         11.40           6 0.3802903 0.02114343 0.33980635 0.4225106
74         11.90           6 0.3939913 0.02058504 0.35444775 0.4349739
75         12.30           6 0.4050746 0.02033786 0.36591716 0.4454784
76         12.70           6 0.4162555 0.02029033 0.37711101 0.4564854
77         13.10           6 0.4275232 0.02045527 0.38798935 0.4680050
78         13.60           6 0.4417130 0.02096514 0.40111035 0.4831103
79         14.00           6 0.4531350 0.02160804 0.41122165 0.4957234
80         14.40           6 0.4646065 0.02244378 0.42100394 0.5087568
81         14.90           6 0.4789972 0.02372774 0.43280610 0.5255503
82         15.30           6 0.4905362 0.02491716 0.44194383 0.5393080
83         15.70           6 0.5020852 0.02622399 0.45084551 0.5532811
84         16.10           6 0.5136320 0.02762421 0.45954129 0.5674053
85         16.60           6 0.5280436 0.02947173 0.47016276 0.5851802
86         17.00           6 0.5395405 0.03100278 0.47848981 0.5994274
87         17.40           6 0.5509955 0.03256125 0.48668685 0.6136432
88         17.90           6 0.5652371 0.03452349 0.49677454 0.6312984
89         18.30           6 0.5765545 0.03608732 0.50473344 0.6452801
90         18.70           6 0.5877922 0.03763233 0.51260450 0.6590948
91         19.10           6 0.5989391 0.03914754 0.52039577 0.6727093
92         19.60           6 0.6127288 0.04098500 0.53003212 0.6894012
93         20.00           6 0.6236332 0.04239948 0.53766482 0.7024623
94         20.40           6 0.6344137 0.04375670 0.54523347 0.7152392
95         20.90           6 0.6477011 0.04536325 0.55460806 0.7307817
96         21.30           6 0.6581701 0.04657002 0.56204087 0.7428532
97         21.70           6 0.6684872 0.04770224 0.56941542 0.7545883
98         22.10           6 0.6786450 0.04875627 0.57673229 0.7659765
99         22.60           6 0.6911076 0.04995944 0.58579753 0.7797114
100        23.00           6 0.7008823 0.05082783 0.59298482 0.7902922
101         2.00          12 0.2665883 0.03139195 0.20970774 0.3324076
102         2.43          12 0.2720193 0.03064731 0.21623636 0.3360230
103         2.86          12 0.2775191 0.02987573 0.22290021 0.3396717
104         3.29          12 0.2830869 0.02907834 0.22969697 0.3433550
105         3.71          12 0.2885899 0.02827585 0.23646127 0.3469880
106         4.14          12 0.2942893 0.02743157 0.24351181 0.3507458
107         4.57          12 0.3000538 0.02656621 0.25068488 0.3545450
108         5.00          12 0.3058823 0.02568193 0.25797551 0.3583886
109         5.43          12 0.3117735 0.02478129 0.26537782 0.3622804
110         5.86          12 0.3177263 0.02386730 0.27288490 0.3662249
111         6.29          12 0.3237393 0.02294352 0.28048860 0.3702275
112         6.71          12 0.3296692 0.02203577 0.28799956 0.3741992
113         7.14          12 0.3357969 0.02110567 0.29576444 0.3783369
114         7.57          12 0.3419805 0.02018063 0.30359218 0.3825564
115         8.00          12 0.3482182 0.01926760 0.31146727 0.3868690
116         8.43          12 0.3545084 0.01837481 0.31937147 0.3912886
117         8.86          12 0.3608493 0.01751202 0.32728338 0.3958321
118         9.29          12 0.3672391 0.01669070 0.33517806 0.4005193
119         9.71          12 0.3735257 0.01594134 0.34284490 0.4052589
120        10.10          12 0.3794018 0.01530477 0.34989816 0.4098249
121        10.60          12 0.3869871 0.01459290 0.35880366 0.4159482
122        11.00          12 0.3930952 0.01412537 0.36577954 0.4210964
123        11.40          12 0.3992370 0.01376436 0.37258947 0.4264949
124        11.90          12 0.4069588 0.01348333 0.38082437 0.4336308
125        12.30          12 0.4131698 0.01340771 0.38716136 0.4396719
126        12.70          12 0.4194084 0.01347185 0.39325825 0.4460193
127        13.10          12 0.4256730 0.01367734 0.39910901 0.4526731
128        13.60          12 0.4335371 0.01412762 0.40608232 0.4614061
129        14.00          12 0.4398528 0.01463304 0.41140392 0.4687025
130        14.40          12 0.4461881 0.01525568 0.41651691 0.4762477
131        14.90          12 0.4541315 0.01617962 0.42264774 0.4859865
132        15.30          12 0.4605034 0.01701950 0.42737124 0.4939883
133        15.70          12 0.4668881 0.01793540 0.43195678 0.5021472
134        16.10          12 0.4732838 0.01891587 0.43642370 0.5104374
135        16.60          12 0.4812904 0.02021662 0.44186635 0.5209488
136        17.00          12 0.4877028 0.02130633 0.44612538 0.5294511
137        17.40          12 0.4941193 0.02243118 0.45031317 0.5380159
138        17.90          12 0.5021424 0.02387631 0.45546318 0.5487843
139        18.30          12 0.5085602 0.02505645 0.45952568 0.5574306
140        18.70          12 0.5149753 0.02625239 0.46354464 0.5660907
141        19.10          12 0.5213854 0.02745958 0.46752581 0.5747523
142        19.60          12 0.5293879 0.02897828 0.47245646 0.5855648
143        20.00          12 0.5357792 0.03019666 0.47636913 0.5941909
144        20.40          12 0.5421589 0.03141462 0.48025706 0.6027858
145        20.90          12 0.5501137 0.03293210 0.48508627 0.6134726
146        21.30          12 0.5564594 0.03413893 0.48892779 0.6219671
147        21.70          12 0.5627867 0.03533682 0.49275191 0.6304048
148        22.10          12 0.5690937 0.03652360 0.49656015 0.6387790
149        22.60          12 0.5769458 0.03798837 0.50130006 0.6491478
150        23.00          12 0.5831997 0.03914296 0.50507695 0.6573567
151         2.00          18 0.3893675 0.05783340 0.28359107 0.5066932
152         2.43          18 0.3906843 0.05572936 0.28837706 0.5036014
153         2.86          18 0.3920027 0.05363441 0.29318505 0.5005404
154         3.29          18 0.3933227 0.05155059 0.29801041 0.4975142
155         3.71          18 0.3946135 0.04952823 0.30273523 0.4945967
156         4.14          18 0.3959365 0.04747373 0.30757850 0.4916542
157         4.57          18 0.3972611 0.04543860 0.31242080 0.4887632
158         5.00          18 0.3985872 0.04342662 0.31725391 0.4859312
159         5.43          18 0.3999147 0.04144222 0.32206827 0.4831669
160         5.86          18 0.4012438 0.03949067 0.32685265 0.4804809
161         6.29          18 0.4025743 0.03757823 0.33159384 0.4778855
162         6.71          18 0.4038752 0.03575518 0.33616811 0.4754521
163         7.14          18 0.4052085 0.03394340 0.34077520 0.4730819
164         7.57          18 0.4065432 0.03219749 0.34528363 0.4708550
165         8.00          18 0.4078793 0.03053005 0.34966762 0.4687962
166         8.43          18 0.4092168 0.02895598 0.35389685 0.4669347
167         8.86          18 0.4105556 0.02749272 0.35793604 0.4653047
168         9.29          18 0.4118957 0.02616029 0.36174482 0.4639454
169         9.71          18 0.4132059 0.02500662 0.36519946 0.4629211
170        10.10          18 0.4144237 0.02408587 0.36813272 0.4622769
171        10.60          18 0.4159864 0.02314742 0.37144646 0.4619420
172        11.00          18 0.4172378 0.02261482 0.37369108 0.4621149
173        11.40          18 0.4184903 0.02229286 0.37554094 0.4627119
174        11.90          18 0.4200574 0.02220177 0.37726743 0.4640837
175        12.30          18 0.4213122 0.02238199 0.37817139 0.4656887
176        12.70          18 0.4225680 0.02278301 0.37865882 0.4677359
177        13.10          18 0.4238248 0.02339448 0.37874958 0.4702044
178        13.60          18 0.4253973 0.02443162 0.37835013 0.4738355
179        14.00          18 0.4266563 0.02545752 0.37766318 0.4771324
180        14.40          18 0.4279163 0.02663709 0.37669006 0.4807360
181        14.90          18 0.4294926 0.02829925 0.37512672 0.4856144
182        15.30          18 0.4307547 0.02975815 0.37363952 0.4897736
183        15.70          18 0.4320176 0.03131523 0.37197464 0.4941270
184        16.10          18 0.4332815 0.03295712 0.37015820 0.4986470
185        16.60          18 0.4348625 0.03511133 0.36770868 0.5044951
186        17.00          18 0.4361283 0.03690435 0.36562903 0.5093074
187        17.40          18 0.4373949 0.03875043 0.36346002 0.5142199
188        17.90          18 0.4389793 0.04112230 0.36064341 0.5204790
189        18.30          18 0.4402478 0.04306424 0.35831949 0.5255658
190        18.70          18 0.4415170 0.04504048 0.35594302 0.5307116
191        19.10          18 0.4427870 0.04704695 0.35352195 0.5359070
192        19.60          18 0.4443755 0.04959232 0.35044320 0.5424590
193        20.00          18 0.4456471 0.05165486 0.34794526 0.5477380
194        20.40          18 0.4469195 0.05373802 0.34542159 0.5530435
195        20.90          18 0.4485109 0.05636772 0.34223717 0.5597043
196        21.30          18 0.4497848 0.05848984 0.33967017 0.5650502
197        21.70          18 0.4510593 0.06062655 0.33708924 0.5704065
198        22.10          18 0.4523345 0.06277646 0.33449710 0.5757693
199        22.60          18 0.4539294 0.06548055 0.33124480 0.5824763
200        23.00          18 0.4552060 0.06765588 0.32863580 0.5878407
201         2.00          24 0.5279854 0.10177834 0.33439434 0.7135102
202         2.43          24 0.5238639 0.09805998 0.33737747 0.7039251
203         2.86          24 0.5197392 0.09434800 0.34032831 0.6941997
204         3.29          24 0.5156118 0.09064719 0.34324041 0.6843471
205         3.71          24 0.5115783 0.08704830 0.34604025 0.6746152
206         4.14          24 0.5074472 0.08338576 0.34885268 0.6645570
207         4.57          24 0.5033152 0.07975214 0.35160038 0.6544219
208         5.00          24 0.4991826 0.07615501 0.35427153 0.6442312
209         5.43          24 0.4950502 0.07260301 0.35685221 0.6340087
210         5.86          24 0.4909184 0.06910609 0.35932596 0.6237816
211         6.29          24 0.4867879 0.06567580 0.36167324 0.6135805
212         6.71          24 0.4827552 0.06240244 0.36382161 0.6036752
213         7.14          24 0.4786288 0.05914554 0.36584629 0.5936329
214         7.57          24 0.4745053 0.05600239 0.36766145 0.5837357
215         8.00          24 0.4703853 0.05299451 0.36922812 0.5740353
216         8.43          24 0.4662693 0.05014708 0.37050027 0.5645909
217         8.86          24 0.4621579 0.04748921 0.37142421 0.5554695
218         9.29          24 0.4580517 0.04505413 0.37193830 0.5467463
219         9.71          24 0.4540464 0.04292617 0.37197892 0.5386893
220        10.10          24 0.4503325 0.04120438 0.37154768 0.5316896
221        10.60          24 0.4455793 0.03940420 0.37024279 0.5235022
222        11.00          24 0.4417838 0.03833028 0.36852277 0.5176696
223        11.40          24 0.4379951 0.03760926 0.36615234 0.5125358
224        11.90          24 0.4332694 0.03722875 0.36223304 0.5071587
225        12.30          24 0.4294976 0.03734674 0.35832678 0.5037078
226        12.70          24 0.4257339 0.03783198 0.35375669 0.5010025
227        13.10          24 0.4219788 0.03866551 0.34856505 0.4990105
228        13.60          24 0.4172977 0.04015506 0.34129205 0.4974471
229        14.00          24 0.4135634 0.04166467 0.33493209 0.4968635
230        14.40          24 0.4098390 0.04341908 0.32817064 0.4968023
231        14.90          24 0.4051981 0.04590430 0.31926418 0.4973628
232        15.30          24 0.4014975 0.04808762 0.31185701 0.4982483
233        15.70          24 0.3978081 0.05041367 0.30426450 0.4994648
234        16.10          24 0.3941303 0.05285769 0.29653954 0.5009660
235        16.60          24 0.3895498 0.05604611 0.28676676 0.5031824
236        17.00          24 0.3858994 0.05868145 0.27890295 0.5051863
237        17.40          24 0.3822618 0.06137530 0.27103466 0.5073648
238        17.90          24 0.3777333 0.06480525 0.26123551 0.5102976
239        18.30          24 0.3741258 0.06758597 0.25345391 0.5127873
240        18.70          24 0.3705322 0.07038930 0.24574516 0.5153867
241        19.10          24 0.3669528 0.07320730 0.23812603 0.5180816
242        19.60          24 0.3624993 0.07674007 0.22874957 0.5215665
243        20.00          24 0.3589533 0.07956737 0.22138075 0.5244350
244        20.40          24 0.3554227 0.08239012 0.21414020 0.5273659
245        20.90          24 0.3510314 0.08590549 0.20528213 0.5311060
246        21.30          24 0.3475365 0.08870266 0.19835776 0.5341515
247        21.70          24 0.3440579 0.09148270 0.19158320 0.5372385
248        22.10          24 0.3405959 0.09424265 0.18496263 0.5403622
249        22.60          24 0.3362923 0.09766025 0.17690830 0.5443119
250        23.00          24 0.3328688 0.10036560 0.17064478 0.5475034

> # covariance matrix of fitted values in linear predictor scale
> vcov(eff.cowles[[1]]) 
              [,1]          [,2]
[1,]  5.422171e-03 -4.091552e-05
[2,] -4.091552e-05  6.957556e-03
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  3.77 0.47 4.27 NA NA 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
